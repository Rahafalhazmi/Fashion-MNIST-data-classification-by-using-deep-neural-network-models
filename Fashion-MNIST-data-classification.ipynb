{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38699125",
   "metadata": {},
   "source": [
    "# CS677 Deep Learning â€“ Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09a7250",
   "metadata": {},
   "source": [
    "#### Rahaf Alhazmi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacc954e",
   "metadata": {},
   "source": [
    "###  The best accuracies are 0.98 for the second model and 0.88 for the frist model, each one of them used a diffrent technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "621b8b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bfcddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare dataset\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f908a90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6c65186",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39b99cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d649f037",
   "metadata": {},
   "source": [
    "### The first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c92510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model by using Keras Sequential API\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([  \n",
    "     keras.layers.Flatten(input_shape=[28, 28]),\n",
    "     keras.layers.BatchNormalization(),\n",
    "     #keras.layers.Dense(100, activation=\"relu\"),\n",
    "     keras.layers.Dense(150, kernel_initializer='he_normal'),\n",
    "      keras.layers.PReLU(),\n",
    "    #keras.layers.BatchNormalization(),\n",
    "    #keras.layers.Dense(50, activation=\"relu\"),\n",
    "     #keras.layers.Dense(100, kernel_initializer='he_normal'),\n",
    "      #keras.layers.PReLU(),\n",
    "     keras.layers.BatchNormalization(),\n",
    "    #keras.layers.Dense(50, activation=\"relu\"),\n",
    "     keras.layers.Dense(50, kernel_initializer='he_normal'),\n",
    "      keras.layers.PReLU(),\n",
    "     keras.layers.BatchNormalization(),\n",
    "      keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8ec2aec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.flatten.Flatten at 0x17e2bc6a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x17e2bcb20>,\n",
       " <keras.layers.core.dense.Dense at 0x17e2bcfd0>,\n",
       " <keras.layers.advanced_activations.PReLU at 0x17e2bcb50>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x17e2ca8b0>,\n",
       " <keras.layers.core.dense.Dense at 0x17e2ea430>,\n",
       " <keras.layers.advanced_activations.PReLU at 0x17e2df760>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x17ea0d130>,\n",
       " <keras.layers.core.dense.Dense at 0x17ea0d2b0>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b03ab4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_6 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 784)              3136      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 150)               117750    \n",
      "                                                                 \n",
      " p_re_lu_10 (PReLU)          (None, 150)               150       \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 150)              600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 50)                7550      \n",
      "                                                                 \n",
      " p_re_lu_11 (PReLU)          (None, 50)                50        \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 50)               200       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 129,946\n",
      "Trainable params: 127,978\n",
      "Non-trainable params: 1,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1d6e8b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f795165",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8b520278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   1/1719 [..............................] - ETA: 10:05 - loss: 3.2832 - accuracy: 0.0312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-11 23:49:54.184687: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - ETA: 0s - loss: 0.5882 - accuracy: 0.7980"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-11 23:50:07.324009: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 14s 8ms/step - loss: 0.5882 - accuracy: 0.7980 - val_loss: 0.4080 - val_accuracy: 0.8584\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 0.4337 - accuracy: 0.8453 - val_loss: 0.3738 - val_accuracy: 0.8724\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 0.3999 - accuracy: 0.8570 - val_loss: 0.3648 - val_accuracy: 0.8738\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 0.3730 - accuracy: 0.8657 - val_loss: 0.3508 - val_accuracy: 0.8756\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 0.3542 - accuracy: 0.8723 - val_loss: 0.3379 - val_accuracy: 0.8820\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 0.3409 - accuracy: 0.8774 - val_loss: 0.3386 - val_accuracy: 0.8792\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 0.3337 - accuracy: 0.8802 - val_loss: 0.3322 - val_accuracy: 0.8840\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 0.3242 - accuracy: 0.8839 - val_loss: 0.3291 - val_accuracy: 0.8822\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 0.3152 - accuracy: 0.8858 - val_loss: 0.3278 - val_accuracy: 0.8834\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 0.3067 - accuracy: 0.8903 - val_loss: 0.3249 - val_accuracy: 0.8864\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "80c6cbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors=[#\"blue\", \"gray\", #  loss      accuracy\n",
    "        \"red\", \"black\"] #   val_loss  val_accuracy\n",
    "                               #df[ [\"val_loss\",\"val_accuracy\"] ].plot(figsize=(8,5), color=colors)\n",
    "pd.DataFrame( history.history )[[\"val_loss\",\"val_accuracy\"]].plot(figsize=(8,5), color=colors)\n",
    "\n",
    "# the validation error is computed at the end of each epoch, while the training error is\n",
    "# computed using a running mean during each epoch. So the training curve should be shifted by\n",
    "# half an epoch to the left.\n",
    "#shift(-0.5)\n",
    "         #1D array                #list\n",
    "plt.plot(np.arange(-0.5,9,1), history.history[\"loss\"], c=\"blue\", label=\"loss\")    #must be put after previous code for plotting Dataframe\n",
    "plt.plot(np.arange(-0.5,9,1), history.history[\"accuracy\"], c=\"gray\", label=\"accuracy\")#must be put after previous code for plotting Dataframe\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8c460887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1692df820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-11 23:52:07.349081: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_new), axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ffb84f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3455 - accuracy: 0.8799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3454783260822296, 0.8799000382423401]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate( X_test, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2491a69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8584000468254089,\n",
       " 0.8724000453948975,\n",
       " 0.8738000392913818,\n",
       " 0.8756000399589539,\n",
       " 0.8820000290870667,\n",
       " 0.8792000412940979,\n",
       " 0.8840000629425049,\n",
       " 0.8822000622749329,\n",
       " 0.883400022983551,\n",
       " 0.886400043964386]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac5ce1f",
   "metadata": {},
   "source": [
    "The test data accuracy for the first model is ~ 0.88. In this model, we used three different techniques and three layers, and the number of neurons is 150, 50, 10, respectively. We achieved this model after many tries with other models and techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7ea58f",
   "metadata": {},
   "source": [
    "### The Second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2d5e887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset\n",
    "\n",
    "def split_dataset(X, y):\n",
    "    y_7_or_8 = (y == 7) | (y == 8) \n",
    "    y_A = y[~y_7_or_8]\n",
    "    y_A[y_A > 8] -= 2 \n",
    "    y_B = (y[y_7_or_8] == 8).astype(np.float32) \n",
    "    return ((X[~y_7_or_8], y_A),\n",
    "            (X[y_7_or_8], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "de7dde0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f1d64121",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f3d0b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f70b0f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   5/1376 [..............................] - ETA: 20s - loss: 2.6170 - accuracy: 0.1000 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-12 00:22:15.603120: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1374/1376 [============================>.] - ETA: 0s - loss: 0.8111 - accuracy: 0.7158"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-12 00:22:31.264378: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1376/1376 [==============================] - 16s 12ms/step - loss: 0.8109 - accuracy: 0.7159 - val_loss: 0.6132 - val_accuracy: 0.7661\n",
      "Epoch 2/20\n",
      "1376/1376 [==============================] - 16s 12ms/step - loss: 0.5364 - accuracy: 0.8051 - val_loss: 0.4994 - val_accuracy: 0.8187\n",
      "Epoch 3/20\n",
      "1376/1376 [==============================] - 16s 12ms/step - loss: 0.4838 - accuracy: 0.8221 - val_loss: 0.4638 - val_accuracy: 0.8327\n",
      "Epoch 4/20\n",
      "1376/1376 [==============================] - 16s 11ms/step - loss: 0.4582 - accuracy: 0.8303 - val_loss: 0.4491 - val_accuracy: 0.8344\n",
      "Epoch 5/20\n",
      "1376/1376 [==============================] - 16s 12ms/step - loss: 0.4404 - accuracy: 0.8358 - val_loss: 0.4349 - val_accuracy: 0.8412\n",
      "Epoch 6/20\n",
      "1376/1376 [==============================] - 16s 12ms/step - loss: 0.4287 - accuracy: 0.8411 - val_loss: 0.4665 - val_accuracy: 0.8194\n",
      "Epoch 7/20\n",
      "1376/1376 [==============================] - 16s 12ms/step - loss: 0.4188 - accuracy: 0.8442 - val_loss: 0.4171 - val_accuracy: 0.8444\n",
      "Epoch 8/20\n",
      "1376/1376 [==============================] - 16s 12ms/step - loss: 0.4097 - accuracy: 0.8471 - val_loss: 0.4139 - val_accuracy: 0.8449\n",
      "Epoch 9/20\n",
      "1376/1376 [==============================] - 16s 12ms/step - loss: 0.4023 - accuracy: 0.8500 - val_loss: 0.4077 - val_accuracy: 0.8487\n",
      "Epoch 10/20\n",
      "1376/1376 [==============================] - 16s 12ms/step - loss: 0.3966 - accuracy: 0.8531 - val_loss: 0.4074 - val_accuracy: 0.8522\n",
      "Epoch 11/20\n",
      "1376/1376 [==============================] - 16s 12ms/step - loss: 0.3905 - accuracy: 0.8559 - val_loss: 0.4016 - val_accuracy: 0.8509\n",
      "Epoch 12/20\n",
      "1376/1376 [==============================] - 16s 12ms/step - loss: 0.3855 - accuracy: 0.8565 - val_loss: 0.4050 - val_accuracy: 0.8524\n",
      "Epoch 13/20\n",
      "1376/1376 [==============================] - 16s 12ms/step - loss: 0.3807 - accuracy: 0.8588 - val_loss: 0.3872 - val_accuracy: 0.8572\n",
      "Epoch 14/20\n",
      "1376/1376 [==============================] - 16s 12ms/step - loss: 0.3760 - accuracy: 0.8613 - val_loss: 0.3878 - val_accuracy: 0.8584\n",
      "Epoch 15/20\n",
      "1376/1376 [==============================] - 16s 12ms/step - loss: 0.3721 - accuracy: 0.8632 - val_loss: 0.3844 - val_accuracy: 0.8589\n",
      "Epoch 16/20\n",
      "1376/1376 [==============================] - 16s 12ms/step - loss: 0.3684 - accuracy: 0.8639 - val_loss: 0.3887 - val_accuracy: 0.8619\n",
      "Epoch 17/20\n",
      "1376/1376 [==============================] - 16s 12ms/step - loss: 0.3640 - accuracy: 0.8650 - val_loss: 0.3819 - val_accuracy: 0.8617\n",
      "Epoch 18/20\n",
      "1376/1376 [==============================] - 29s 21ms/step - loss: 0.3601 - accuracy: 0.8670 - val_loss: 0.4012 - val_accuracy: 0.8527\n",
      "Epoch 19/20\n",
      "1376/1376 [==============================] - 16s 12ms/step - loss: 0.3575 - accuracy: 0.8685 - val_loss: 0.3763 - val_accuracy: 0.8619\n",
      "Epoch 20/20\n",
      "1376/1376 [==============================] - 16s 12ms/step - loss: 0.3543 - accuracy: 0.8692 - val_loss: 0.3710 - val_accuracy: 0.8629\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e741f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "989ad18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5eac1a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1290f454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.7628 - accuracy: 0.4688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-12 00:27:51.860432: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - ETA: 0s - loss: 0.7458 - accuracy: 0.4900"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-12 00:27:52.129897: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 67ms/step - loss: 0.7458 - accuracy: 0.4900 - val_loss: 0.5656 - val_accuracy: 0.7435\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 45ms/step - loss: 0.5366 - accuracy: 0.7500 - val_loss: 0.4401 - val_accuracy: 0.8513\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.4235 - accuracy: 0.8550 - val_loss: 0.3543 - val_accuracy: 0.9102\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.3466 - accuracy: 0.9050 - val_loss: 0.3011 - val_accuracy: 0.9361\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.2955 - accuracy: 0.9500 - val_loss: 0.2624 - val_accuracy: 0.9491\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.2566 - accuracy: 0.9650 - val_loss: 0.2333 - val_accuracy: 0.9571\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.2273 - accuracy: 0.9800 - val_loss: 0.2114 - val_accuracy: 0.9581\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.2054 - accuracy: 0.9750 - val_loss: 0.1944 - val_accuracy: 0.9671\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.1874 - accuracy: 0.9850 - val_loss: 0.1794 - val_accuracy: 0.9671\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.1726 - accuracy: 0.9850 - val_loss: 0.1673 - val_accuracy: 0.9701\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.1593 - accuracy: 0.9850 - val_loss: 0.1571 - val_accuracy: 0.9701\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.1486 - accuracy: 0.9850 - val_loss: 0.1481 - val_accuracy: 0.9721\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 45ms/step - loss: 0.1391 - accuracy: 0.9850 - val_loss: 0.1407 - val_accuracy: 0.9741\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 0.1312 - accuracy: 0.9850 - val_loss: 0.1343 - val_accuracy: 0.9750\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 0.1247 - accuracy: 0.9850 - val_loss: 0.1288 - val_accuracy: 0.9750\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.1179 - accuracy: 0.9850 - val_loss: 0.1236 - val_accuracy: 0.9760\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 0.1126 - accuracy: 0.9850 - val_loss: 0.1190 - val_accuracy: 0.9770\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 0.1073 - accuracy: 0.9850 - val_loss: 0.1146 - val_accuracy: 0.9770\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 0.1028 - accuracy: 0.9850 - val_loss: 0.1107 - val_accuracy: 0.9770\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 48ms/step - loss: 0.0989 - accuracy: 0.9850 - val_loss: 0.1073 - val_accuracy: 0.9770\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8d0d3a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_12 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 275,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "da054ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7aa85ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c9ca8f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "42fbb1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6454 - accuracy: 0.6200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-12 00:27:57.969888: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-12 00:27:58.185767: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 65ms/step - loss: 0.6454 - accuracy: 0.6200 - val_loss: 0.6492 - val_accuracy: 0.6038\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.6219 - accuracy: 0.6400 - val_loss: 0.6270 - val_accuracy: 0.6158\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.6005 - accuracy: 0.6450 - val_loss: 0.6055 - val_accuracy: 0.6317\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.5797 - accuracy: 0.6750 - val_loss: 0.5833 - val_accuracy: 0.6567\n",
      "Epoch 1/16\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 0.4744 - accuracy: 0.8125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-12 00:27:59.378766: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - ETA: 0s - loss: 0.4730 - accuracy: 0.8150"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-12 00:27:59.667183: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 70ms/step - loss: 0.4730 - accuracy: 0.8150 - val_loss: 0.3810 - val_accuracy: 0.9012\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 45ms/step - loss: 0.3358 - accuracy: 0.9300 - val_loss: 0.3029 - val_accuracy: 0.9481\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 0.2719 - accuracy: 0.9700 - val_loss: 0.2528 - val_accuracy: 0.9611\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 49ms/step - loss: 0.2300 - accuracy: 0.9800 - val_loss: 0.2208 - val_accuracy: 0.9671\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 0.2016 - accuracy: 0.9800 - val_loss: 0.1965 - val_accuracy: 0.9721\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.1799 - accuracy: 0.9900 - val_loss: 0.1781 - val_accuracy: 0.9770\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 0.1633 - accuracy: 0.9900 - val_loss: 0.1622 - val_accuracy: 0.9790\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.1492 - accuracy: 0.9900 - val_loss: 0.1504 - val_accuracy: 0.9780\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.1384 - accuracy: 0.9900 - val_loss: 0.1397 - val_accuracy: 0.9810\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 48ms/step - loss: 0.1287 - accuracy: 0.9900 - val_loss: 0.1314 - val_accuracy: 0.9820\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 0.1211 - accuracy: 0.9900 - val_loss: 0.1244 - val_accuracy: 0.9820\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.1149 - accuracy: 0.9900 - val_loss: 0.1185 - val_accuracy: 0.9810\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.1093 - accuracy: 0.9900 - val_loss: 0.1132 - val_accuracy: 0.9830\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.1044 - accuracy: 0.9900 - val_loss: 0.1082 - val_accuracy: 0.9840\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 45ms/step - loss: 0.1000 - accuracy: 0.9900 - val_loss: 0.1040 - val_accuracy: 0.9840\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 0.0960 - accuracy: 0.9900 - val_loss: 0.1003 - val_accuracy: 0.9850\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dc64c843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1002 - accuracy: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10022583603858948, 0.984000027179718]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4e8ca4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0931 - accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09308028221130371, 0.9890000224113464]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aedeb4",
   "metadata": {},
   "source": [
    "The test data accuracy for the second model is ~ 0.98 for model B and 0.99 for model b on A. In this model, we used Reusing Pretrained Layers technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3c4936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
